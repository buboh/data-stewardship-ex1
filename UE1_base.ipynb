{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UE1_base.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "53aWeqYg4e7K",
        "Y0N7wshF4e7L",
        "E2XFru2GKP2z",
        "YwBLCRFOzNLl",
        "w0qhwnOKdj0O",
        "LqQ2nxeYh8yX",
        "kVDYsazlBLIb",
        "ICMeoPQmdmY-",
        "x8jTTgLwFdhI",
        "CAOLvWGkN4Si"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "53aWeqYg4e7K",
        "colab_type": "text",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "# Datasets #\nBreast Cancer: https://www.kaggle.com/c/184702-tu-ml-ws-18-breast-cancer/data\n* Small # samples (285)\n* Small # dimensions (32)\n* Small # classes (2)\n\nArrythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia\n* Small # samples (452)\n* Large # dimensions (279)\n* Large # classes (16)\n"
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Y0N7wshF4e7L",
        "colab_type": "text",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "# Models # \n* [Decision Tree](https://scikit-learn.org/stable/modules/tree.html)\n* [kNN](https://scikit-learn.org/stable/modules/neighbors.html)"
    },
    {
      "metadata": {
        "id": "T0zOCMg0QSNa",
        "colab_type": "text",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "# General"
    },
    {
      "metadata": {
        "id": "Z0Fkluju9LjL",
        "colab_type": "code",
        "outputId": "b87d2b85-9825-4b64-d587-cff732d52e87",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1543152025052,
          "user_tz": -60,
          "elapsed": 4639,
          "user": {
            "displayName": "David Penz",
            "photoUrl": "",
            "userId": "10978165602958476716"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "mlpath \u003d \"C:/Users/Moritz/Desktop/DS-UE1/\"",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YwBLCRFOzNLl",
        "colab_type": "text",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "## Module Installs \u0026 Imports"
    },
    {
      "metadata": {
        "id": "Yx_BVAvNzDqz",
        "colab_type": "code",
        "colab": {},
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "\n# Import Modules\nimport pydotplus\nimport graphviz \nimport datetime as dt\nimport pandas as pd\nimport numpy as np\nimport sklearn as sk\nfrom sklearn import neighbors\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom sklearn import svm\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree \nfrom IPython.display import Image    \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.decomposition import PCA\n\nimport matplotlib.pyplot as plt\n\n# allows to output plots in the notebook\n%matplotlib inline",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eahb91VrDFZ_",
        "colab_type": "text",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "# Classifiers\n## Preprocessing"
    },
    {
      "metadata": {
        "id": "C4Mq-14dNdVV",
        "colab_type": "code",
        "colab": {},
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "# scale data\ndef scale_data(train_data, test_data \u003d pd.DataFrame):\n  scaler \u003d preprocessing.StandardScaler()\n  \n  # Fit on training set only.\n  scaler.fit(train_data)\n  \n  # Apply transform to both the training set and the test set.\n  train_data[train_data.columns] \u003d pd.DataFrame(scaler.transform(train_data[train_data.columns]))\n  if test_data.empty:\n    return train_data\n  else:\n    test_data[test_data.columns] \u003d pd.DataFrame(scaler.transform(test_data[test_data.columns]))\n    return train_data, test_data\n\n# strip whitespaces\ndef strip(data):\n  return data.apply(lambda x: x.str.strip())\n\n# replace empty strings with nan\ndef fillspace_nan(data):\n  return data.apply(lambda x: x.replace(\u0027\u0027, np.nan))\n\n# one hot encoding\ndef one_hot(data, drop_first \u003d True):\n  columns \u003d data.select_dtypes([\u0027object\u0027])\n  return pd.get_dummies(data, columns \u003d columns, drop_first \u003d True)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mMTBPabyTDrz",
        "colab_type": "text",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## Cross-validation"
      ]
    },
    {
      "metadata": {
        "id": "Qqcsk1EETHcx",
        "colab_type": "code",
        "colab": {},
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": [
        "# num_cv \u003d # splits\n",
        "def run_cv(classifier, train_data, train_target, num_cv \u003d 10):\n",
        "  scores_acc \u003d model_selection.cross_val_score(classifier, train_data, train_target, cv \u003d num_cv)\n",
        "  scores_f1 \u003d model_selection.cross_val_score(classifier, train_data, train_target, cv \u003d num_cv, scoring \u003d \u0027f1_macro\u0027, n_jobs \u003d -1)\n",
        "  print(\"Accuracy: %0.3f (+/- %0.3f), F1: %0.3f (+/- %0.3f)\" % (scores_acc.mean(), scores_acc.std(), scores_f1.mean(), scores_f1.std()))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zZGaTozDO7n",
        "colab_type": "text",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ]
    },
    {
      "metadata": {
        "id": "845Q5ijir-Vz",
        "colab_type": "code",
        "colab": {},
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "# Run KNN \ndef run_knn(train_data, train_target, test_data, test_target, k \u003d 5, col_name \u003d \u0027predict\u0027, skip_cv \u003d False):  \n  # define classifier\n  knn \u003d neighbors.KNeighborsClassifier(n_neighbors \u003d k)\n  # train\n  knn.fit(train_data, train_target)\n  # predict\n  knnresult \u003d pd.DataFrame(knn.predict(test_data), columns \u003d [col_name])\n  # cross validation\n  if not skip_cv:\n    print(\"CV: {}\".format(k))\n    run_cv(knn, train_data, train_target)\n  return knnresult, knn\n\n# Create KNN result\ndef create_knn_result(train_data, train_target, test_data, test_target, k, col_name, skip_cv \u003d False):\n  (knnresult, knn) \u003d run_knn(train_data, train_target, test_data, test_target, k, col_name, skip_cv)\n  \n  print(\"KNN\", knn.score(test_data, test_target))\n  print(metrics.confusion_matrix(test_target, knnresult))\n  \n  return knnresult, knn\n\n# Create KNN filename\ndef knn_filename(k, scale):\n  filename \u003d \u0027knn_{}{}_{}.csv\u0027.format(k, \u0027_scaled\u0027 if scale else \u0027\u0027, str(dt.datetime.now()))\n  return filename\n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPAjp5dPDST8",
        "colab_type": "text",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "## DTREE"
    },
    {
      "metadata": {
        "id": "d3uCZ-MNhoF9",
        "colab_type": "code",
        "colab": {},
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "# Run DTREE\ndef run_dtree(train_data, train_target, test_data, test_target, criterion \u003d \u0027entropy\u0027, max_depth \u003d None, post_prune \u003d False, col_name \u003d \u0027predict\u0027, skip_cv \u003d False):\n  # define classifier\n  dtree_clf \u003d DecisionTreeClassifier(criterion \u003d criterion, max_depth \u003d max_depth)\n  # train\n  dtree_clf.fit(train_data, train_target)\n  # predict\n  dtreeresult \u003d pd.DataFrame(dtree_clf.predict(test_data), columns \u003d [col_name])\n  # cross validation\n  if (not skip_cv):\n    print(\"CV: [Criterion] {}, [Max Tree Depth] {}\".format(criterion, max_depth))\n    run_cv(dtree_clf, train_data, train_target)\n  return (dtreeresult, dtree_clf)\n\n# Plot Decision Tree\ndef plot_tree(dtree_clf): \n  dot_data \u003d StringIO()\n  export_graphviz(dtree_clf, out_file \u003d dot_data,  \n                  filled \u003d True, rounded \u003d True,\n                  special_characters \u003d True)\n  graph \u003d pydotplus.graph_from_dot_data(dot_data.getvalue())\n  return Image(graph.create_png())\n\n# Create DTREE results\ndef create_dtree_results(train_data, train_target, test_data, test_target, criterion, max_depth, post_prune, col_name, skip_cv):\n  (dtreeresult, dtree_clf) \u003d run_dtree(train_data, train_target, test_data, test_target, criterion, max_depth, post_prune, col_name, skip_cv)\n  \n  print(\"DTREE \", dtree_clf.score(test_data, test_target)) \n  print(metrics.confusion_matrix(test_target, dtreeresult))\n\n  return dtreeresult, dtree_clf\n\n# Create DTREE filename\ndef dtree_filename(criterion, max_depth, post_prune):\n  filename \u003d \u0027dtree_{}_{}{}_{}.csv\u0027.format(criterion, str(max_depth), \u0027_pp\u0027 if post_prune else \u0027\u0027, str(dt.datetime.now()))\n  return filename",
      "execution_count": 7,
      "outputs": []
    }
  ]
}